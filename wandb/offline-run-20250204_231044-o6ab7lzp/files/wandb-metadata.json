{
  "os": "Linux-5.15.0-130-generic-x86_64-with-glibc2.31",
  "python": "CPython 3.10.16",
  "startedAt": "2025-02-04T19:10:45.005657Z",
  "args": [
    "--model_name_or_path",
    "liuhaotian/llava-v1.6-mistral-7b",
    "--version",
    "v1",
    "--data_path",
    "/home/mmd/RL4VLM/RL4VLM/sft-data/sft-data/points24/points24.json",
    "--image_folder",
    "/home/mmd/RL4VLM/RL4VLM/sft-data/sft-data/points24/points24_data_folder",
    "--vision_tower",
    "openai/clip-vit-large-patch14-336",
    "--mm_projector_type",
    "mlp2x_gelu",
    "--mm_vision_select_layer",
    "-2",
    "--mm_use_im_start_end",
    "False",
    "--mm_use_im_patch_token",
    "False",
    "--image_aspect_ratio",
    "pad",
    "--group_by_modality_length",
    "True",
    "--bf16",
    "True",
    "--output_dir",
    "/home/mmd/RL4VLM/sft_checkpoint",
    "--num_train_epochs",
    "1",
    "--per_device_train_batch_size",
    "4",
    "--per_device_eval_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "1",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "50000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-5",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--tf32",
    "True",
    "--model_max_length",
    "2048",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--lazy_preprocess",
    "True"
  ],
  "program": "/home/mmd/RL4VLM/RL4VLM/LLaVA/llava/train/train_mem.py",
  "codePath": "RL4VLM/LLaVA/llava/train/train_mem.py",
  "git": {
    "remote": "https://github.com/RL4VLM/RL4VLM.git",
    "commit": "b989b57400ad1010306fe170a547b57e7d21389c"
  },
  "root": "/home/mmd/RL4VLM/RL4VLM",
  "host": "m15",
  "executable": "/home/mmd/miniconda3/envs/llava/bin/python3",
  "codePathLocal": "LLaVA/llava/train/train_mem.py",
  "cpu_count": 8,
  "cpu_count_logical": 8,
  "gpu": "NVIDIA GeForce RTX 3090",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "97827328000",
      "used": "78562365440"
    }
  },
  "memory": {
    "total": "33560018944"
  },
  "cpu": {
    "count": 8,
    "countLogical": 8
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.2"
}